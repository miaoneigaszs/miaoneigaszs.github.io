import os
import hashlib
import streamlit as st
from uuid import uuid4
from functools import partial
from typing import Annotated, Literal, Sequence
from typing_extensions import TypedDict

# --- æ ¸å¿ƒä¾èµ– ---
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient
from qdrant_client.http.models import VectorParams, Distance, Filter, FieldCondition, MatchValue
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.tools.retriever import create_retriever_tool
from langchain_core.messages import BaseMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import END, StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from pydantic import BaseModel, Field
from dotenv import load_dotenv

load_dotenv()


# --- é…ç½® ---
os.environ["USER_AGENT"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# ğŸ”¥ å…³é”®ä¿®æ”¹1: æ–°çš„é›†åˆå
COLLECTION_NAME = "rag_bge_fixed_v2" 
VECTOR_SIZE = 512  

st.set_page_config(page_title="ç½‘ç«™æ£€å½•ä¸é—®ç­”RAG", page_icon="ğŸ”§", layout="wide")

# --- çŠ¶æ€å®šä¹‰ ---
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    loop_step: int
    run_mode: str
    
qdrant_host = os.getenv("QDRANT_HOST")
qdrant_api_key = os.getenv("QDRANT_API_KEY")
openai_api_key = os.getenv("OPENAI_API_KEY")


# --- Session State ---
if 'qdrant_host' not in st.session_state: st.session_state.qdrant_host = qdrant_host
if 'qdrant_api_key' not in st.session_state: st.session_state.qdrant_api_key = qdrant_api_key
if 'openai_api_key' not in st.session_state: st.session_state.openai_api_key = openai_api_key
if "indexed_urls" not in st.session_state: st.session_state.indexed_urls = set()

# --- 1. URL å»é‡è¾…åŠ©å‡½æ•° ---
def get_url_hash(url: str) -> str:
    """ç”Ÿæˆ URL çš„ MD5 å“ˆå¸Œå€¼"""
    return hashlib.md5(url.encode()).hexdigest()

def check_url_exists_in_db(client: QdrantClient, url: str) -> bool:
    """æ£€æŸ¥ URL æ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“"""
    url_hash = get_url_hash(url)
    result = client.scroll(
        collection_name=COLLECTION_NAME,
        scroll_filter=Filter(
            must=[FieldCondition(
                key="metadata.url_hash",
                match=MatchValue(value=url_hash)
            )]
        ),
        limit=1
    )
    return len(result[0]) > 0

def get_all_indexed_urls(client: QdrantClient) -> set:
    """ä»æ•°æ®åº“è·å–æ‰€æœ‰å·²ç´¢å¼•çš„ URLï¼ˆå¯åŠ¨æ—¶åŒæ­¥ç”¨ï¼‰"""
    # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
    if not client.collection_exists(COLLECTION_NAME):
        return set()
    
    urls = set()
    offset = None
    while True:
        result = client.scroll(
            collection_name=COLLECTION_NAME,
            limit=100,
            offset=offset,
            with_payload=True
        )
        points, offset = result
        if not points:
            break
        for point in points:
            if point.payload and "metadata" in point.payload:
                url = point.payload["metadata"].get("source")
                if url:
                    urls.add(url)
        if offset is None:
            break
    return urls

def create_url_index(client: QdrantClient):
    """ä¸º url_hash åˆ›å»ºç´¢å¼•ï¼ŒåŠ é€ŸæŸ¥è¯¢"""
    try:
        client.create_payload_index(
            collection_name=COLLECTION_NAME,
            field_name="metadata.url_hash",
            field_schema="keyword"
        )
    except Exception:
        pass  # ç´¢å¼•å·²å­˜åœ¨åˆ™å¿½ç•¥

def handle_old_documents(client: QdrantClient, delete: bool = False) -> int:
    """ç»Ÿè®¡æˆ–åˆ é™¤æ²¡æœ‰ url_hash çš„æ—§æ–‡æ¡£
    Args:
        delete: False=ä»…ç»Ÿè®¡, True=ç»Ÿè®¡å¹¶åˆ é™¤
    Returns:
        æ—§æ–‡æ¡£æ•°é‡
    """
    # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
    if not client.collection_exists(COLLECTION_NAME):
        return 0
    
    ids_to_delete = []
    offset = None
    while True:
        result = client.scroll(
            collection_name=COLLECTION_NAME,
            limit=100,
            offset=offset,
            with_payload=True
        )
        points, offset = result
        if not points:
            break
        for point in points:
            if point.payload:
                metadata = point.payload.get("metadata", {})
                if "url_hash" not in metadata:
                    ids_to_delete.append(point.id)
        if offset is None:
            break
    
    if delete and ids_to_delete:
        client.delete(
            collection_name=COLLECTION_NAME,
            points_selector=ids_to_delete
        )
    return len(ids_to_delete)

# --- 2. èµ„æºåˆå§‹åŒ– ---
@st.cache_resource(show_spinner="æ­£åœ¨åŠ è½½ BGE æ¨¡å‹...")
def get_resources(qdrant_host, qdrant_api_key):
    try:
        model_name = "BAAI/bge-small-zh-v1.5"
        model_kwargs = {'device': 'cpu'}
        encode_kwargs = {'normalize_embeddings': True}
        
        embedding_model = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs,
        )

        client = QdrantClient(qdrant_host, api_key=qdrant_api_key)

        if not client.collection_exists(COLLECTION_NAME):
            client.create_collection(
                collection_name=COLLECTION_NAME,
                vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)
            )

        # åˆ›å»º url_hash ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
        create_url_index(client)

        db = QdrantVectorStore(
            client=client,
            collection_name=COLLECTION_NAME,
            embedding=embedding_model
        )
        return db, client  # åŒæ—¶è¿”å› client
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None, None

# --- 2. LLM ---
def get_llm(api_key, json_mode=False):
    return ChatOpenAI(
        model="gpt-4o-mini",
        openai_api_key=api_key,
        openai_api_base="https://openai.api2d.net/v1",
        temperature=0,
        model_kwargs={"response_format": {"type": "json_object"}} if json_mode else {}
    )

# --- 3. æ ¸å¿ƒèŠ‚ç‚¹ ---
def grade_documents(state, api_key) -> Literal["generate", "rewrite"]:
    mode = state.get("run_mode", "deep")
    
    if mode == "fast":
        print("ğŸš€ å¿«é€Ÿæ¨¡å¼")
        return "generate"

    print("---ğŸ” GRADE ---")
    current_step = state.get("loop_step", 0)

    if current_step >= 3:
        return "generate"

    class Grade(BaseModel):
        binary_score: str = Field(description="'yes' or 'no'")

    model = get_llm(api_key)
    llm_with_tool = model.with_structured_output(Grade)

    # ğŸ”¥ å…³é”®ä¿®æ”¹3: æ›´å®½å®¹çš„è¯„åˆ†æç¤º
    prompt = ChatPromptTemplate.from_template(
        """ä½ æ˜¯è¯„åˆ†å‘˜ã€‚è¯„ä¼°æ£€ç´¢ç‰‡æ®µæ˜¯å¦èƒ½å›ç­”é—®é¢˜ã€‚
        
        è§„åˆ™ï¼š
        1. å¦‚æœç‰‡æ®µåŒ…å«é—®é¢˜ä¸­æåˆ°çš„æ¦‚å¿µ/æœ¯è¯­çš„å®šä¹‰æˆ–è§£é‡Šï¼Œè¯„ä¸º 'yes'
        2. å³ä½¿ç”¨è¯ä¸å®Œå…¨åŒ¹é…ï¼ˆå¦‚"æ¦‚å¿µ"vs"å®šä¹‰"ï¼‰ï¼Œä½†è¯­ä¹‰ç›¸å…³ï¼Œä¹Ÿè¯„ä¸º 'yes'
        3. åªæœ‰å®Œå…¨æ— å…³æ—¶æ‰è¯„ä¸º 'no'
        
        é—®é¢˜: {question}
        ç‰‡æ®µ: {context}
        
        è¯„åˆ† (yes/no):"""
    )
    
    messages = state["messages"]
    question = messages[0].content
    docs = messages[-1].content
    
    print(f"ğŸ‘‰ é—®é¢˜: {question}")
    print(f"ğŸ“„ ç‰‡æ®µ: {docs[:100]}...")

    chain = prompt | llm_with_tool
    score = chain.invoke({"question": question, "context": docs}).binary_score

    if score == "yes":
        print("âœ… é€šè¿‡")
        return "generate"
    else:
        print("âŒ é‡å†™")
        return "rewrite"

def agent(state, tools, api_key):
    print("---ğŸ¤– AGENT ---")
    model = get_llm(api_key).bind_tools(tools)
    response = model.invoke(state["messages"])
    return {"messages": [response]}

def rewrite(state, api_key):
    print("---âœï¸ REWRITE ---")
    question = state["messages"][0].content
    current_step = state.get("loop_step", 0)
    
    # ğŸ”¥ å…³é”®ä¿®æ”¹4: æ›´æ™ºèƒ½çš„é‡å†™ç­–ç•¥
    prompt = ChatPromptTemplate.from_template(
        """ä½ çš„ä»»åŠ¡æ˜¯é‡å†™é—®é¢˜ä»¥æé«˜æ£€ç´¢æ•ˆæœã€‚
        
        åŸé—®é¢˜: {question}
        
        é‡å†™è§„åˆ™ï¼š
        - ä¿ç•™æ ¸å¿ƒæ¦‚å¿µè¯
        - ç”¨å¤šä¸ªåŒä¹‰è¯è¡¨è¾¾ï¼ˆå¦‚"æ¦‚å¿µ"å¯ä»¥è¯´æˆ"å®šä¹‰ã€å«ä¹‰ã€è§£é‡Š"ï¼‰
        - ç®€åŒ–ä¸ºé™ˆè¿°å¥å½¢å¼
        
        é‡å†™åçš„é—®é¢˜:"""
    )
    
    chain = prompt | get_llm(api_key) | StrOutputParser()
    rewritten = chain.invoke({"question": question})
    print(f"ğŸ“ é‡å†™ç»“æœ: {rewritten}")
    
    return {
        "messages": [HumanMessage(content=rewritten)], 
        "loop_step": current_step + 1
    }

def generate(state, api_key):
    print("---ğŸ’¡ GENERATE ---")
    messages = state["messages"]
    question = messages[0].content
    
    docs = ""
    for m in reversed(messages):
        if m.type == "tool":
            docs = m.content
            break
    
    if not docs:
        docs = "æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ã€‚"

    # ğŸ”¥ å…³é”®ä¿®æ”¹5: æ›´æ¸…æ™°çš„ç”Ÿæˆæç¤º
    prompt = ChatPromptTemplate.from_template(
        """ä½ æ˜¯ä¸€ä¸ªè´´å¿ƒã€ç²¾å‡†çš„é—®ç­”åŠ©æ‰‹ã€‚
        
        ã€æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µã€‘:
        {context}
        
        ã€ç”¨æˆ·é—®é¢˜ã€‘:
        {question}
        
        ã€è¦æ±‚ã€‘:
        1. å¦‚æœæ–‡æ¡£ä¸­æœ‰å®Œæ•´å®šä¹‰ï¼Œç›´æ¥å¼•ç”¨
        2. ä¸è¦è¯´"æ ¹æ®æ–‡æ¡£"ä¹‹ç±»çš„å¥—è¯
        3. è¯­ä¹‰ç›¸å…³çš„è¡¨è¿°è§†ä¸ºåŒ¹é…ï¼ˆå¦‚"æ¦‚å¿µ"="å®šä¹‰"ï¼‰
        4. å¦‚æœä½ è®¤ä¸ºæ–‡æ¡£å†…å®¹æ²¡æœ‰æ¸…æ™°å›ç­”é—®é¢˜ï¼Œæˆ–è€…ä¸å¤Ÿè¯¦ç»†ä»¥åŠæ¸…æ¥šï¼Œè¿˜æ˜¯éœ€è¦æ ¹æ®æ–‡æ¡£å†…å®¹è¿›ä¸€æ­¥åˆ†æï¼Œä¿è¯åˆ‡å®æœ‰æ•ˆè§£å†³ç”¨æˆ·çš„é—®é¢˜ï¼Œæ¯”å¦‚ä½ è®¤ä¸ºä¸å¤Ÿæ¸…æ™°ï¼Œå¯ä»¥è¯¦ç»†è§£é‡Šï¼Œæˆ–è¿›ä¸€æ­¥é˜è¿°
        
        ã€ä½ çš„å›ç­”ã€‘:"""
    )
    
    rag_chain = prompt | get_llm(api_key) | StrOutputParser()
    response = rag_chain.invoke({"context": docs, "question": question})
    return {"messages": [response]}

# --- 4. æ„å»ºå›¾ ---
def get_graph(retriever_tool, api_key):
    tools = [retriever_tool]
    workflow = StateGraph(AgentState)

    workflow.add_node("agent", partial(agent, tools=tools, api_key=api_key))
    workflow.add_node("retrieve", ToolNode(tools))
    workflow.add_node("rewrite", partial(rewrite, api_key=api_key))
    workflow.add_node("generate", partial(generate, api_key=api_key))

    workflow.add_edge(START, "agent")
    workflow.add_conditional_edges("agent", tools_condition, {"tools": "retrieve", END: END})
    workflow.add_conditional_edges("retrieve", partial(grade_documents, api_key=api_key))
    workflow.add_edge("generate", END)
    workflow.add_edge("rewrite", "agent")

    return workflow.compile()

# --- 5. è¾…åŠ©å‡½æ•° ---
def add_documents_to_db(url, db, client):
    try:
        # åŒé‡æ£€æŸ¥ï¼šå…ˆæ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨
        if check_url_exists_in_db(client, url):
            return False, "URL å·²å­˜åœ¨äºæ•°æ®åº“ä¸­"
        
        url_hash = get_url_hash(url)
        loader = WebBaseLoader(url)
        docs = loader.load()
        
        # ä¸ºæ¯ä¸ªæ–‡æ¡£æ·»åŠ  url_hash å…ƒæ•°æ®
        for doc in docs:
            doc.metadata["url_hash"] = url_hash
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=300,
            chunk_overlap=100,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""]
        )
        doc_chunks = text_splitter.split_documents(docs)
        
        print(f"\nğŸ“¦ åˆ‡åˆ†äº† {len(doc_chunks)} ä¸ªç‰‡æ®µ:")
        for i, chunk in enumerate(doc_chunks[:3]):
            print(f"  [{i}] {chunk.page_content[:100]}...")
        
        uuids = [str(uuid4()) for _ in range(len(doc_chunks))]
        db.add_documents(documents=doc_chunks, ids=uuids)
        return True, len(doc_chunks)
    except Exception as e:
        return False, str(e)

def generate_message(graph, inputs):
    final_ans = ""
    for output in graph.stream(inputs):
        for key, value in output.items():
            if key == "generate":
                msg = value["messages"][0]
                final_ans = msg if isinstance(msg, str) else msg.content
    return final_ans

# --- Main UI ---
def main():
    with st.sidebar:
        st.subheader("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        run_mode = st.radio(
            "è¿è¡Œæ¨¡å¼:",
            ["ğŸš€ å¿«é€Ÿç›´é€š", "ğŸ§  æ·±åº¦è¯„æµ‹"],
            index=0
        )
        mode_code = "fast" if "å¿«é€Ÿ" in run_mode else "deep"
        
        st.divider()
        st.subheader("ğŸ”‘ API é…ç½®")
        q_host = st.text_input("Qdrant Host", value=st.session_state.qdrant_host, type="password")
        q_key = st.text_input("Qdrant Key", value=st.session_state.qdrant_api_key, type="password")
        oa_key = st.text_input("API2D Key", value=st.session_state.openai_api_key, type="password")
        
        if st.button("ğŸ’¾ ä¿å­˜"):
            st.session_state.qdrant_host = q_host
            st.session_state.qdrant_api_key = q_key
            st.session_state.openai_api_key = oa_key
            st.success("å·²ä¿å­˜")

    st.title("ğŸ”§ ä¿®å¤ç‰ˆä¸­æ–‡ RAG")

    if not all([st.session_state.qdrant_host, st.session_state.qdrant_api_key, st.session_state.openai_api_key]):
        st.info("ğŸ‘ˆ è¯·å…ˆé…ç½® API")
        return

    # è·å– db å’Œ client
    result = get_resources(st.session_state.qdrant_host, st.session_state.qdrant_api_key)
    if result[0] is None:
        return
    db, client = result

    # ğŸ”¥ å¯åŠ¨æ—¶åŒæ­¥ï¼šä»æ•°æ®åº“åŠ è½½å·²ç´¢å¼•çš„ URL
    if "urls_synced" not in st.session_state:
        try:
            db_urls = get_all_indexed_urls(client)
            st.session_state.indexed_urls.update(db_urls)
            st.session_state.urls_synced = True
        except Exception as e:
            st.warning(f"åŒæ­¥ URL å¤±è´¥: {e}")

    retriever = db.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 10,
            "fetch_k": 20,
            "lambda_mult": 0.7
        }
    )
    retriever_tool = create_retriever_tool(
        retriever, 
        "retrieve_blog_posts", 
        "æœç´¢åšå®¢ä¸­çš„æ¦‚å¿µå®šä¹‰å’Œè§£é‡Š"
    )

    # ğŸ“š çŸ¥è¯†åº“ç®¡ç†
    with st.expander("ğŸ“š çŸ¥è¯†åº“ç®¡ç†", expanded=True):
        # URL å½•å…¥åŒº
        st.markdown("#### æ·»åŠ æ–° URL")
        col1, col2 = st.columns([3, 1])
        url = col1.text_input("URL:", label_visibility="collapsed", placeholder="https://...")
        if col2.button("ğŸ“¥ å­˜å…¥"):
            if url:
                # åŒé‡æ£€æŸ¥ï¼šå…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
                if url in st.session_state.indexed_urls:
                    st.warning("âš ï¸ è¯¥ URL å·²å­˜åœ¨ï¼ˆå†…å­˜ç¼“å­˜ï¼‰")
                else:
                    with st.spinner("æ£€æŸ¥å¹¶çˆ¬å–ä¸­..."):
                        success, msg = add_documents_to_db(url, db, client)
                        if success:
                            st.session_state.indexed_urls.add(url)
                            st.success(f"âœ… å­˜å…¥ {msg} ä¸ªç‰‡æ®µ")
                        else:
                            if "å·²å­˜åœ¨" in str(msg):
                                # æ•°æ®åº“ä¸­å­˜åœ¨ä½†æœ¬åœ°ç¼“å­˜æ²¡æœ‰ï¼ŒåŒæ­¥ä¸€ä¸‹
                                st.session_state.indexed_urls.add(url)
                                st.warning(f"âš ï¸ {msg}")
                            else:
                                st.error(f"âŒ {msg}")
        
        st.divider()
        
        # å·²ç´¢å¼• URL åˆ—è¡¨ï¼ˆç®€æ´æ˜¾ç¤ºï¼‰
        url_count = len(st.session_state.indexed_urls)
        if url_count > 0:
            with st.expander(f"ğŸ“‹ å·²ç´¢å¼• {url_count} ä¸ª URL", expanded=False):
                for url in st.session_state.indexed_urls:
                    st.code(url, language=None)
        else:
            st.info("æš‚æ— å·²ç´¢å¼•çš„ URL")
        
        st.divider()
        
        # æ—§æ•°æ®æ¸…ç†ï¼ˆåˆå¹¶ä¸ºä¸€ä¸ªæŒ‰é’®ï¼‰
        if st.button("ğŸ§¹ æ£€æŸ¥å¹¶æ¸…ç†æ—§æ•°æ®"):
            with st.spinner("å¤„ç†ä¸­..."):
                count = handle_old_documents(client, delete=False)
                if count > 0:
                    deleted = handle_old_documents(client, delete=True)
                    st.success(f"âœ… å·²æ¸…ç† {deleted} ä¸ªæ—§æ–‡æ¡£")
                    st.session_state.urls_synced = False
                    st.rerun()
                else:
                    st.success("âœ… æ— éœ€æ¸…ç†ï¼Œæ‰€æœ‰æ–‡æ¡£éƒ½æœ‰ url_hash")

    # é—®ç­”åŒº
    if st.session_state.indexed_urls:
        st.divider()
        query = st.text_area("ğŸ§  æé—®:", height=100, placeholder="ä¾‹å¦‚ï¼šåŒåŒ–çš„æ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ")
        
        col1, col2 = st.columns([1, 4])
        run_btn = col1.button("â–¶ï¸ è¿è¡Œ", use_container_width=True)
        test_btn = col2.button("ğŸ” æµ‹è¯•æ£€ç´¢ï¼ˆè°ƒè¯•ç”¨ï¼‰", use_container_width=True)
        
        if test_btn and query:
            with st.spinner("æ£€ç´¢ä¸­..."):
                docs = retriever.invoke(query)
                st.write(f"æ£€ç´¢åˆ° {len(docs)} ä¸ªç‰‡æ®µ:")
                for i, doc in enumerate(docs[:5]):
                    st.info(f"**[{i}]** {doc.page_content[:200]}...")
        
        if run_btn and query:
            graph = get_graph(retriever_tool, st.session_state.openai_api_key)
            inputs = {
                "messages": [HumanMessage(content=query)], 
                "loop_step": 0,
                "run_mode": mode_code
            }
            
            with st.spinner(f"è¿è¡Œä¸­ ({mode_code})..."):
                try:
                    ans = generate_message(graph, inputs)
                    if ans:
                        st.markdown("### ğŸ“ å›ç­”:")
                        st.success(ans)
                    else:
                        st.error("æœªèƒ½ç”Ÿæˆå›ç­”")
                except Exception as e:
                    st.error(f"é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()